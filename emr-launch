#!/bin/bash
set -e
trap cleanup_spinner `seq 0 15`
trap cleanup_cluster INT
cleanup_cluster() {
    if [ -n "$cluster_id" ]; then 
        echo "Terminating ... cluster ID: ${cluster_id}"; 
        aws2 emr terminate-clusters --cluster-ids "$cluster_id"
        sleep 5
    fi
    exit
}
cleanup_spinner() {
    if [ -n "${spin_pid}" ]; then
        pkill -9 $spin_pid
    fi
}

s3_check_exists() {
    aws2 s3api head-bucket --bucket "${1}" 2>/dev/null
}




spin() {
  spinner="/|\\-/|\\-"
  while :
  do
    for i in `seq 0 7`
    do
      echo -n "${spinner:$i:1}"
      echo -en "\010"
      sleep 1
    done
  done
}

# -------------––-------------- parsing arguments -----------------------------
cluster_id=''
spot='false'
region="${AWS_DEFAULT_REGION}"
label="${EMR_DEFAULT_LABEL}"
num_worker=4
deploy='false'
theia='false'
force='false'
bootstrap_path="${BOOTSTRAPE_PATH}"
pid="${PID}"

while getopts 'u:bfvr:l:k:n:dp:t' flag; do
  case "${flag}" in
    u) pid="${OPTARG}" ;;
    b) spot='true' ;;
    r) region="${OPTARG}" ;;
    l) label="${OPTARG}" ;;
    k) key="${OPTARG}" ;;
    n) num_worker=${OPTARG} ;;
    d) deploy='true' ;;
    p) bootstrap_path="${OPTARG}" ;;
    t) theia='true' ;;
    f) force='true' ;;
    ?) printf '\nUsage: %s: [-u:] your pid [-b] if set, use spot [-r:] region [-l:] EMR label
     [-k:] key name [-n:] number of workers
     [-p:] bootstrap script path [-d] if set, use the deployment hardware m5.xlarge
     [-t] if set, setup theia IDE on master node port 3000 [-f] if set, force start the second cluster\n' $0; exit 2 ;;
  esac
done

declare -a arr_name=('-k')
declare -a arr=("$key")

for ((i=0;i<${#arr[@]};++i)); do
    if [ -z "${arr[i]}" ]; then
        echo "Error: argument ${arr_name} is required."
        exit 1
    fi
done
# -------------––--------------------------------------------------------------

# -------------––----------------- S3 checks ----------------------------------

s3_bucket_logs=${pid}${S3_LOGS_POSTFIX}
s3_bucket_scripts=${pid}${S3_PA2_POSTFIX}
s3_bucket_scripts_folder=${s3_bucket_scripts}/${S3_PA2_SRC_FOLDER}
s3_buckets=("${s3_bucket_logs}" "${s3_bucket_scripts}")
for bucket in "${s3_buckets[@]}"; do
    if !(s3_check_exists $bucket); then
        echo "Error: S3 bucket of $bucket does not exist or the token has expired. Run s3-init first or update your credentials.list."
        exit 1
    fi
done
# -------------––--------------------------------------------------------------


# -------------––-------------- spawning cluster ------------------------------

id_list=$(emr-list)
if [ -n "${id_list}" ]; then
    echo "Warning: following cluster(s) is already running"
    echo "$id_list"
    if [ "${force}" = "false" ]; then
        echo "Error: to spawn multiple clusters, set -f flag"
        exit 1
    fi
fi
emr_cluster=${pid}${EMR_CLUSTER_POSTFIX}
if [ "$deploy" = 'true' ]; then
    instance_type="m5.xlarge"
else
    instance_type="m4.large"
fi

if [ "$spot" = 'true' ]; then
    instance_group_core="InstanceCount=$num_worker,InstanceType=$instance_type,BidPrice=OnDemandPrice"
else
    instance_group_core="InstanceCount=$num_worker,InstanceType=$instance_type"    
fi
# -------------––--------------------------------------------------------------

# ------------------------------ spawn cluster --------------------------------

ret=$(aws2 emr create-cluster \
--release-label "${label}" \
--instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=$instance_type InstanceGroupType=CORE,"$instance_group_core" \
--use-default-roles \
--ec2-attributes KeyName="${key}"  \
--applications Name=Spark Name=Hadoop \
--name="$emr_cluster" \
--log-uri s3://"${s3_bucket_logs}" \
--bootstrap-actions Path="$bootstrap_path",Args=["${pid}","s3://${s3_bucket_scripts_folder}","${region}","${theia}"] \
--configurations '[{"Classification":"spark","Properties":{"maximizeResourceAllocation":"true","spark.dynamicAllocation.enabled":"false"}}]'
) &&
cluster_id=$(echo $ret | jq -r '.ClusterId')

if [  -z "$cluster_id" ]; then
    echo "cluster failed to start"
    exit 1
fi

echo "Cluster starting ... cluster ID: ${cluster_id}"

spin &
sleep 20
state=''
spin_pid=$!
until [ "$state" = "WAITING" ]; do
    state=$(aws2 emr describe-cluster --cluster-id "${cluster_id}" | jq -r .Cluster.Status.State)
    printf "            Current cluster state: ${state}              \r"
    if [[ ("${state}" = "TERMINATED") || ("${state}" = "TERMINATING") || ("${state}" = "TERMINATED_WITH_ERRORS") ]]; then
        echo " Cluster terminated accidently. Check logs on AWS console."
        break
    fi
    sleep 5
done

if [ "$state" = "WAITING" ]; then
    printf "\nCluster is up\n"
fi
kill -9 $spin_pid
spin_pid=''
ret=$(aws2 emr describe-cluster --cluster-id "${cluster_id}")
dns_name=$(echo $ret | jq -r '.Cluster.MasterPublicDnsName')
echo "Cluster specs: cluster id: ${cluster_id}, region: ${region}, instance type: ${instance_type}, worker number: ${num_worker}, spot option: ${spot}"
echo "Master public DNS name: ${dns_name}, user name: hadoop"
echo "Updating security groups ..."
set +e
for i in "22 SSH" "8888 Jupyter-Notebook" "3000 Theia-IDE" "18080 Spark-history-UI" "20888 Spark-UI"
do
    set -- $i
    aws2 ec2 authorize-security-group-ingress \
    --group-name "ElasticMapReduce-master" \
    --protocol tcp \
    --port ${1} \
    --cidr 0.0.0.0/0 \
    > /dev/null 2>&1
done
aws2 ec2 authorize-security-group-ingress \
    --group-name "ElasticMapReduce-slave" \
    --ip-permissions '[{"IpProtocol": "tcp", "FromPort": 22, "ToPort": 22, "IpRanges": [{"CidrIp": "0.0.0.0/0", "Description": "SSH access"}]}]' \
    > /dev/null 2>&1
# -------------––--------------------------------------------------------------

