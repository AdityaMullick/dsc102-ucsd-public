#!/bin/bash
set -e
trap cleanup INT
cleanup() {
    if [ -n "$cluster_id" ]; then 
        echo "Terminating ... cluster ID: ${cluster_id}"; 
        aws2 emr terminate-clusters --cluster-ids "$cluster_id"
        sleep 5
    fi
    exit
}

update_script_bucket(){
    n=0
    retrytime=3
    until aws2 s3api head-bucket --bucket "$s3_bucket_scripts" 2>/dev/null; do
        if [ $n -ge $retrytime ]; then
            break
        fi
        ((++n))
        echo "Bucket not up, retrying ..."
        sleep 20
    done

    if [ $n -le $retrytime ]; then
        aws2 s3api put-bucket-versioning --bucket "${s3_bucket_scripts}" --versioning-configuration Status=Enabled
        aws2 s3 sync "s3://dsc102-pa2" "s3://${s3_bucket_scripts_folder}"
    else
        echo "Bucket not up, retry timeout"
        exit 1
    fi
}

s3_block_public() {
    aws2 s3api put-public-access-block --bucket $1 \
        --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
}

s3_check_exists() {
    aws2 s3api head-bucket --bucket "${1}"
}

s3_create_bucket() {
    aws2 s3api create-bucket --acl private \
        --bucket "${1}" \
        --region "${region}" \
        --create-bucket-configuration LocationConstraint="${region}"
}

# -------------––-------------- parsing arguments -----------------------------
cluster_id=''
spot='false'
region='us-west-2'
label='emr-5.28.0'
num_worker=4
deploy='false'
theia='false'
force='false'
bootstrap_path='s3://dsc102-pa2-public/bootstrap-scripts/setup-common.sh'


while getopts 'u:bf:vr:l:k:n:d:p:t' flag; do
  case "${flag}" in
    u) pid="${OPTARG}" ;;
    b) spot='true' ;;
    r) region="${OPTARG}" ;;
    l) label="${OPTARG}" ;;
    k) key="${OPTARG}" ;;
    n) num_worker=${OPTARG} ;;
    d) deploy='true' ;;
    p) bootstrap_path="${OPTARG}" ;;
    t) theia='true' ;;
    f) force='true' ;;
    ?) printf '\nUsage: %s: [-u:] your pid [-b] if set, use spot [-r:] region [-l:] EMR label
     [-k:] key name [-n:] number of workers [-d] if set, use deployment env
     [-p:] bootstrap script path 
     [-t] if set, setup theia IDE on master node port 3000 [-f] if set, force start the second cluster\n' $0; exit 2 ;;
  esac
done

declare -a arr_name=('-p' '-k')
declare -a arr=("$pid" "$key")

for ((i=0;i<${#arr[@]};++i)); do
    if [ -z "${arr[i]}" ]; then
        echo "Error: argument ${arr_name} is required."
        exit 1
    fi
done
# -------------––--------------------------------------------------------------

# -------------––-------------- setting up bucket -----------------------------
s3_bucket_logs=${pid}-emr-logs
s3_bucket_scripts=${pid}-pa2
s3_bucket_scripts_folder=${s3_bucket_scripts}/src

if [[ -n "$pid" ]]; then
    if s3_check_exists "${s3_bucket_logs}"; then
        echo "EMR logs bucket ${s3_bucket_logs} already exists, skipping"
    else
        echo "Creating emr logs bucket: ${s3_bucket_logs}"
        s3_create_bucket "${s3_bucket_logs}"
        s3_block_public "${s3_bucket_logs}"
    fi
    if s3_check_exists "${s3_bucket_scripts}"; then
        echo "Scripts bucket ${s3_bucket_scripts} already exists, updating the bucket with missing files"
        update_script_bucket
    else
        echo "Creating scripts bucket: ${s3_bucket_scripts}"
        s3_create_bucket "${s3_bucket_scripts}" &&
        echo "Copying PA2 scripts ..."
        update_script_bucket

    fi
else
    echo "Argument error: pid"
    exit 1
fi
# -------------––--------------------------------------------------------------

# -------------––-------------- spawning cluster ------------------------------
emr_cluster=${pid}-emr-cluster
if [ "$deploy" = 'true' ]; then

    instance_type="m5.xlarge"
else
    instance_type="m4.large"
fi

if [ "$spot" = 'true' ]; then
    instance_group_core="InstanceCount=$num_worker,InstanceType=$instance_type,BidPrice=OnDemandPrice"
else
    instance_group_core="InstanceCount=$num_worker,InstanceType=$instance_type"    
fi

ret=$(aws2 emr create-cluster \
--release-label "${label}" \
--instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=$instance_type InstanceGroupType=CORE,"$instance_group_core" \
--use-default-roles \
--ec2-attributes KeyName="${key}"  \
--applications Name=Spark Name=Hadoop \
--name="$emr_cluster" \
--log-uri s3://"${s3_bucket_logs}" \
--bootstrap-actions Path="$bootstrap_path",Args=["${pid}","s3://${s3_bucket_scripts_folder}","${region}","${theia}"] \
--configurations '[{"Classification":"spark","Properties":{"maximizeResourceAllocation":"true","spark.dynamicAllocation.enabled":"false"}}]'
) &&
cluster_id=$(echo $ret | jq -r '.ClusterId')

if [  -z "$cluster_id" ]; then
    echo "cluster failed to start"
    exit
fi

echo "Cluster starting ... cluster ID: ${cluster_id}"


sleep 20
state=''
until [ "$state" = "WAITING" ]; do
    state=$(aws2 emr describe-cluster --cluster-id "${cluster_id}" | jq -r .Cluster.Status.State)
    printf "Current cluster state: ${state}\r"
    if [[ ("${state}" = "TERMINATED") || ("${state}" = "TERMINATING") || ("${state}" = "TERMINATED_WITH_ERRORS") ]]; then
        echo "Cluster terminated accidently. Check logs on AWS console."
        break
    fi
    sleep 20
done

if [ "$state" = "WAITING" ]; then
    printf "\nCluster is up\n"
fi

ret=$(aws2 emr describe-cluster --cluster-id "${cluster_id}")
dns_name=$(echo $ret | jq -r '.Cluster.MasterPublicDnsName')
echo "Cluster specs: cluster id: ${cluster_id}, region: ${region}, instance type: ${instance_type}, worker number: ${num_worker}, spot option: ${spot}"
echo "Master public DNS name: ${dns_name}, user name: hadoop"
# -------------––--------------------------------------------------------------

